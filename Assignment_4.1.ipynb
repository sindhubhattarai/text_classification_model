{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "### Sindhu Bhattarai\n",
    "\n",
    "### Assignment 4.1\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import emoji\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place any addtional functions or constants you need here. \n",
    "\n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def common_tokens(tokens):\n",
    "    return (Counter(tokens).most_common())\n",
    "\n",
    "    \n",
    "# def is_emoji(s):\n",
    "#     return(emoji.is_emoji(s))\n",
    "\n",
    "# def contains_emoji(s):    \n",
    "#     s = str(s)\n",
    "#     emojis = [ch for ch in s if is_emoji(ch)]\n",
    "\n",
    "#     return(len(emojis) > 0)\n",
    "\n",
    "\n",
    "def remove_stop(text, stop_words = sw) :\n",
    "     # modify this function to remove stopwords\n",
    "    return(\" \".join([word for word in text.split(' ') if word not in stop_words ]))\n",
    "\n",
    "\n",
    "#changes as per the assignment requirement\n",
    "punctuation.add('â€™')\n",
    "punctuation.add('\" \"')\n",
    "tw_punct = punctuation #- {\"#\"}\n",
    "\n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) : \n",
    "    # modified this function to return tokens of word only \n",
    "    return text.split(\" \")\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.casefold()\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('conventions',)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_name = convention_cur.execute(\"SELECT name FROM sqlite_master\")\n",
    "stored_name.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = [str.lower, remove_punctuation, remove_stop,tokenize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT *  \n",
    "                            FROM conventions\n",
    "                            ''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the rows of stored value \n",
    "# for row in query_results :\n",
    "#     print(row[5])\n",
    "    #print(row[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convention_data = []\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "\n",
    "\n",
    "for row in query_results :\n",
    "    text = row[5]\n",
    "    # Thefirst element in the sublist should be the cleaned and tokenized(using pipeline)\n",
    "    clean_text = prepare(text, pipeline = my_pipeline) \n",
    "    #tokenized text should be in a single string \n",
    "    string_text = \" \".join(clean_text)\n",
    "    #The second element should be the party.\n",
    "    party = row[0] \n",
    "    data_to_append = [string_text, party] \n",
    "    convention_data.append(data_to_append)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convention_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young people watching dont give america despite flaws problems weve come far still equal country opportunities previous generations could never imagined theres lot heartbreak america truth many things broken pandemic saying goes world breaks everyone afterward many strong broken places thats joe biden knows keep going unify lead hes done family country come november strong together well heal together well redeem soul',\n",
       "  'Democratic'],\n",
       " ['built beautiful family circle trust', 'Democratic'],\n",
       " ['lets clear vaccine racism got work george floyd brianna taylor lives many others name children us weve got work fulfill promise equal justice law heres thing none us free us free',\n",
       "  'Democratic'],\n",
       " ['obama biden led united nations denounce friend ally israel president trump moved embassy jerusalem un tried condemn us proud cast american veto president record strength success former vice president record weakness failure joe biden good iran isis great communist china hes godsend everyone wants america apologize abstain abandon values donald trump takes different approach hes tough china took isis tells world needs hear',\n",
       "  'Republican'],\n",
       " ['working people backbone economy key recovery joe biden knows enough praise reward lets raise minimum wage 15 hour empower workers negotiate better benefits safer workplaces make easier pay things like healthcare higher education proud cast 24 votes bernie sanders 25 votes next president joe biden',\n",
       "  'Democratic'],\n",
       " ['next president right', 'Democratic'],\n",
       " ['foreign language 002807 15yearold refugee vietnam knew education key finding opportunities new home children became advocate improve public education system gave chance contribute america democrat invest educations committed fighting kids washington cast 43 votes senator bernie sanders 66 votes next president joe biden',\n",
       "  'Democratic'],\n",
       " ['democrats working bridge divides make sure everyone equal access low nocost quality care today oregon cast 16 votes bernie sandersâ€¦ rosa colquitt  012328   â€¦and senators wyden merkleys support cast 57 votes joe biden',\n",
       "  'Democratic'],\n",
       " ['really economic empowerment people lifted poverty given opportunity feel stake future goes long way also challenging kinds institutions corporations community based organizations think better end systemic racism make sure uplifting quality life communities also voices people traditionally dont seat table',\n",
       "  'Democratic'],\n",
       " ['please', 'Republican']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2387 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "# tokens = [i for i in tokens if not i in sw] \n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    \n",
    "    ret_dict = dict()\n",
    "    token = text.lower().split()\n",
    "    for word in token:\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "        \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quick': True, 'fox': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features('QuiCk QuiCk brOwn foX',{'quick','fox','jumps'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]\n",
    "#featuresets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "I can see that among top 25 token which are most informative features by classifier most of the tokens are more often used by republican with very high ratio in comparision.\n",
    "The tokens \"climate\" and \"votes\" are mostly used by democratic party. As we know democrats talked about climate change in heafty amount in 2020 election which teh classifier definitely addressess. \n",
    "\n",
    "We can see that the token such as \"enforcement\", \"china\",\"defense\", \"crime\", \"trade\", \"destroy\", \"freedoms\",\"drug\",\"isis\", \"wonderful\" are more are heavily used by republicans more than democrats. These words undoubtedly represents the sentiments of rebublicans and their representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the rows of stored value \n",
    "#for row in results:\n",
    "#     print(row[1])\n",
    "    #print(row[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for row in results :\n",
    "    #tweets is in row[2] and decoding b prefix from the data\n",
    "    tweets = row[2].decode('utf-8')\n",
    "   # Thefirst element in the sublist should be the cleaned and tokenized(using pipeline)\n",
    "    clean_tweets = prepare(tweets, pipeline = my_pipeline) \n",
    "    #tokenized text should be in a single string \n",
    "    string_tweets = \" \".join(clean_tweets)\n",
    "    #The second element should be the party.\n",
    "    party = row[1] \n",
    "    tweetdata_to_append = [string_tweets, party] \n",
    "    tweet_data.append(tweetdata_to_append)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv',\n",
       "  'Democratic'],\n",
       " ['go tribe rallytogether httpstco0nxutfl9l5', 'Democratic'],\n",
       " ['apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqo5t0qh',\n",
       "  'Democratic'],\n",
       " ['grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line\\n\\nhttpstcoezpv0vmiz3',\n",
       "  'Republican'],\n",
       " ['lets make even greater  kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z', 'Republican'],\n",
       " ['1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory',\n",
       "  'Democratic'],\n",
       " ['congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi',\n",
       "  'Democratic'],\n",
       " ['really close 3500 raised toward match right whoot thats 7000 nonmath majors room ðŸ˜‚ help us get httpstcotu34c472sd httpstcoqsdqkypsmc',\n",
       "  'Democratic'],\n",
       " ['today comment period potuss plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn',\n",
       "  'Democratic'],\n",
       " ['celebrated icseastlas 22 years eastside commitment amp saluted community leaders last nights awards dinner httpstco7v7gh8givb',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(20201014)\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)\n",
    "tweet_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line\n",
      "\n",
      "httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: lets make even greater  kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot thats 7000 nonmath majors room ðŸ˜‚ help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potuss plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastlas 22 years eastside commitment amp saluted community leaders last nights awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(conv_features(tweet,feature_words))\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(conv_features(tweet,feature_words))\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3724, 'Democratic': 554}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4834, 'Democratic': 890})})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "We can see in the above results that for overall republican tweets  3724 classified as rebublican and 554 classified as democratic. \n",
    "Similarly, out of Democratic tweets 4834 classified as republican and 890 as democratic. \n",
    "\n",
    "Our classifier is classifying rebublican more accurately than democratic. It falsely classifies democratic as republican in heavy number. Overall we can say that the classifier is not doing a good job here. There can be various reason which can lead to classifier not working accurately. Some of them are:\n",
    "\n",
    "1. There can be class imbalance. More unique tokens of rebublican than of democratic party.\n",
    "2. Some other classifier might work better than naive bayes for our data. Here the classifier is overfitting for republican class and underfitting for democratic class. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
